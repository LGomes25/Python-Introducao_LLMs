import streamlit as st
import fitz
import io
from langchain_core.documents import Document
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.document_loaders import PyMuPDFLoader
from chatbot import app, State


def main():

    # Configura칞칚o da p치gina e t칤tulo
    st.set_page_config(
        layout="wide", page_title="Chatbot de loja de bicicletas", page_icon="游뛊"
    )
    st.title("Loja de Bicicletas - Assistente Virtual")

    # Inicializa hist칩rico com mensagem de boas-vindas
    if "message_history" not in st.session_state:
        st.session_state["message_history"] = [
            AIMessage(
                content="Ol치! 游뛊 Sou seu assistente virtual da loja de bicicletas. Como posso ajudar voc칡 com bicicletas? Envie um PDF ou pergunte algo!"
            )
        ]

    # Upload e leitura de arquivo PDF
    uploaded_file = st.file_uploader(
        "Fa칞a o upload de um PDF para an치lise", type=["pdf"]
    )
    pdf_text = ""

    if uploaded_file is not None:
        # L칡 o conte칰do do arquivo em mem칩ria
        file_bytes = uploaded_file.read()
        # Cria um buffer de bytes para o fitz
        with fitz.open(stream=io.BytesIO(file_bytes), filetype="pdf") as doc:
            pdf_text = "\n".join([str(page.get_text("text")) for page in doc])

    # Entrada do usu치rio
    user_input = st.chat_input("Digite aqui...")

    # Adiciona mensagem do usu치rio ao hist칩rico
    if user_input:
        st.session_state["message_history"].append(HumanMessage(content=user_input))

    # Caixa para streaming
    msg_box = st.chat_message("assistant")

    # Invoca o backend com pergunta e contexto
    state: State = {
        "pergunta": user_input or "",
        "contexto": [Document(page_content=pdf_text, metadata={})],
        "resposta": "",
    }
    response_stream = app.invoke(state)["resposta"]

    # Montar resposta palavra por palavra
    full_response = ""
    for chunk in msg_box.write_stream(response_stream):
        full_response += chunk  # cada bloco tem .content

    # Atualiza hist칩rico com a resposta do modelo
    st.session_state["message_history"].append(AIMessage(content=full_response))

    # Renderiza hist칩rico na interface
    for i in range(2, len(st.session_state["message_history"]) + 1):
        msg = st.session_state["message_history"][-i]
        message_box = st.chat_message(
            "assistant" if isinstance(msg, AIMessage) else "user"
        )
        message_box.markdown(msg.content)


if __name__ == "__main__":
    main()
